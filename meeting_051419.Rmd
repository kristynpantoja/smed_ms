---
title: 'Meeting : 14 May 2019'
author: "Kristyn Pantoja"
date: "5/3/2019"
output: 
  beamer_presentation:
    toc: true
    includes:
      in_header: header.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Last Time

## Evaluating Model Ideas

Tried to evaluate the model based on:

1. Robustness
    - what happens when the power $k = 0:1$ in one-at-a-time algorithm
    - what happens when the number of designs $K$ gets large (how it affects $\gamma_k$) in fast algorithm
2. Objective Improvement 
    - Total Potential Energy

# Today

## The Plan

1. Fix optimization thing in first step

2. Make a table!

- Methods: 
  - One-at-a-Time Algorithm
  - Fast Algorithm
  - Random design
  - Space-Filling design 
  - D-Optimal design (is there one for model selection? e.g. one for $H_0$ and one for $H_1$? criterion doesn't seem to incorporate that.)
  - etc.
- Evaluations: 
  - Expected Posterior Probabilities of $H_0, H_1$ & Bayes Factors of data generated from each $H_0, H_1$ model
  - Regression variance on coefficient (slope here)
  - Total Potential Energy criterion
  - One-at-a-Time Algorithm criterion
  - Fast Algorithm criterion


## Regression Variance

- In the case where $y_i = x_i \beta + \varepsilon_i$ (with a fixed $\beta$) with $\varepsilon_i ~ N(0, \sigma_\varepsilon^2)$, we have:

$$
\hat{\beta} \sim N \left( \beta, \frac{\sigma_\varepsilon^2}{\sum_{i = 1}^N(x_i - \bar{x})^2} \right)
$$

Since $\hat{\beta} = \frac{\sum_i (y_i - \bar{y})(x_i - \bar{x})}{\sum_i (x_i - \bar{x})} = \sum_i w_i y_i$, where $w_i = \frac{(x_i - \bar{x})}{\sum_j (x_j - \bar{x})^2}$, and so $Var[\hat{\beta}] = Var[\sum_i w_i y_i] = Var[\sum_i w_i (x_i \beta + \varepsilon_i)] = \sum_i w_i^2 Var[\varepsilon_i] = \sigma_\varepsilon^2 \sum w_i^2$.

- It is similar when $\beta \sim N(\tilde{\beta}, \sigma_\beta^2)$:

- After marginalizing out $\beta$, $y_i \sim N(x_i \tilde{\beta}, \sigma_\varepsilon^2 + x_i^2 \sigma_\beta^2)$. Hence:

$Var[\hat{\beta}] = Var[\sum_i w_i y_i]= \sum_i w_i^2 Var[y_i] = \sum_i w_i^2 (\sigma_\varepsilon^2 + x_i^2 \sigma_\beta^2)$



## Criterions

1. The total potential energy, which both algorithms aim to minimize:

$$
\sum_{i \neq j} \frac{q(\mathbf{x}_i) q(\mathbf{x}_j)}{d(\mathbf{x}_i, \mathbf{x}_j)}
$$

2. One-at-a-Time Algorithm criterion tries to minimize: 

$$
\left\{ \sum_{i \neq j} \left( \frac{q(\mathbf{x}_i) q(\mathbf{x}_j)}{d(\mathbf{x}_i, \mathbf{x}_j)} \right)^k \right\} ^{1/k}
$$

3. Fast Algorithm tries to minimize:

$$
\max_{i \neq j} \frac{q(\mathbf{x}_i) q(\mathbf{x}_j)}{d(\mathbf{x}_i, \mathbf{x}_j)}
$$



## Parameters

```{r sources, include = FALSE}
library(transport)
library(mined)
library(expm)
source("/Users/kristyn/Documents/research/smed_ms/smed_ms_functions.R")
```

- Parameters

```{r parameters, echo = TRUE}
mean_beta0 = 1 # slope of null model
mean_beta1 = 1 / 2 # slope of alternative model
var_mean = 0.001 # variance on beta
var_e = 0.01 # variance on error
```

- Settings for Fast and One-at-a-Time algorithms

```{r settings, include = FALSE}
xmin = 0 
xmax = 1 

f0 = function(x) mean_beta0 * x # null regression model
f1 = function(x) mean_beta1 * x # alternative regression model
```

```{r settings2, echo = TRUE}
N = 67
# for fast algorithm:
K = 20 # ceiling(4* sqrt(p))
numParameters = 1 # number of parameters (just slope!)
p = numParameters * 2
# for one-at-a-time algorithm:
numCandidates = 10^5 # suggested 10^5
k = 4
```



# Fast Algorithm

## Design generated by Fast Algorithm

```{r alg1run, cache = TRUE}
## Fast Algorithm
X_fast = SMED_ms_fast(mean_beta0 = mean_beta0, mean_beta1 = mean_beta1, var_e = var_e, var_mean = var_mean, N = N, xmin = xmin, xmax = xmax, K = K, p = p)
```

```{r, fig.height = 6}
par(mfrow = c(1, 2))
# design points' locations
X_fast_K = X_fast$D[ , K]
curve(f0, col = 1, from = xmin, to = xmax, xlab = "", ylab = "", ylim = c(0, 3), axes = FALSE)
curve(f1, col = 1, add = TRUE)
axis(1)
y = rep(NA, N)
for(i in 1:N){
  y[i] = i * 0.04
  text(X_fast$D[i ,K], y[i], i, col=4)
}
points(X_fast_K, rep(0, N), col = 2, pch = "*")
lines(X_fast_K, y, col = 3)
# histogram of design points
hist(X_fast_K, freq = T)
```

\tiny
```{r, echo = TRUE}
mean(X_fast_K)
sd(X_fast_K)
```


<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r, include = FALSE}
# USE THESE AT SOME POINT
library("foreach")
library("doParallel")
library("doRNG")

numSims = 1000
nworkers = detectCores()
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_0 --> 

```{r alg1bfh0, include = FALSE, cache = TRUE}
# Simulate several Y and average to compare Posteriors H_i | X, Y

X = X_fast_K

## 1st suppose H_0 is true, i.e. y_i = x_i beta0 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1
YH0_fast <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta0 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta0
randSim = sample(1:numSims, 1); plot(YH0_fast[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y (given H0) at each row and column, for each model
getMarginalY = function(x, mean_beta, i) dnorm(x, mean = mean_beta * X[i], sd = sqrt(var_e))

marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH0_fast[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH0_fast[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH0fast = mean(marginalY_H0); expect_margY_H1_YH0fast = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH0fast = expect_margY_H0_YH0fast / (expect_margY_H0_YH0fast + expect_margY_H1_YH0fast)
expect_post_H1_YH0fast = expect_margY_H1_YH0fast / (expect_margY_H0_YH0fast + expect_margY_H1_YH0fast)
BF01_YH0fast = expect_margY_H0_YH0fast / expect_margY_H1_YH0fast # since > 1, H0 is supported
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_1 --> 

```{r alg1bfh1, include = FALSE, cache = TRUE}
## 2nd suppose H_1 is true, i.e. y_i = x_i beta1 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1

YH1fast <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta1 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta1
randSim = sample(1:numSims, 1); plot(YH1fast[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH1fast[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH1fast[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH1fast = mean(marginalY_H0); expect_margY_H1_YH1fast = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH1fast = expect_margY_H0_YH1fast / (expect_margY_H0_YH1fast + expect_margY_H1_YH1fast)
expect_post_H1_YH1fast = expect_margY_H1_YH1fast / (expect_margY_H0_YH1fast + expect_margY_H1_YH1fast)
BF01_YH1fast = expect_margY_H0_YH1fast / expect_margY_H1_YH1fast # since < 1, H0 is not supported
```

<!-- Variance of Slope, Total Potential Energy, c1, c2 Evaluations --> 

```{r alg1evals}
# Regression variance of slope, not taking beta prior into account
v_fast = varslope(X_fast_K, var_e, var_mean)
# Total Potential Energy criterion
TPE_fast = totalPE(X_fast_K, N, mean_beta0, mean_beta1, var_e, var_mean)
# Fast Algorithm criterion
c1_fast = crit_fast(X_fast_K, N, mean_beta0, mean_beta1, var_e, var_mean)
# One-at-a-Time Algorithm criterion
c2_fast = crit_1atatime(X_fast_K, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean)

evals_fast = c(expect_post_H0_YH0fast, expect_post_H1_YH0fast, BF01_YH0fast, expect_post_H0_YH1fast, expect_post_H1_YH1fast, BF01_YH1fast, v_fast, TPE_fast, c1_fast, c2_fast, mean(X_fast_K), sd(X_fast_K))
```

## Evaluations

```{r, echo = TRUE}
# Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0fast, expect_post_H1_YH0fast, BF01_YH0fast)
# Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1fast, expect_post_H1_YH1fast, BF01_YH1fast)
# Slope Variance
v_fast
# Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_fast, c1_fast, c2_fast)
```


## Over the K Designs

\tiny
```{r alg1crits}
par(mfrow = c(2, 2))

varslope_each_k = rep(NA, K)
for(k in 1:K){
  varslope_each_k[k] = varslope(X_fast$D[ , k], var_e, var_mean)
}
plot(varslope_each_k, type = "l", xlab = "k = 1:K", ylab = "Slope Variance", axes = F)
box()

totalPEfast_each_k = rep(NA, K)
for(k in 1:K){
  totalPEfast_each_k[k] = totalPE(X_fast$D[ , k], N, mean_beta0, mean_beta1, var_e, var_mean)
}
plot(totalPEfast_each_k, type = "l", xlab = "k = 1:K", ylab = "Total Potential Energy", axes = F)
box()

critfast_each_k = rep(NA, K)
for(i in 1:K){
  critfast_each_k[i] = crit_fast(X_fast$D[ , i], N, mean_beta0, mean_beta1, var_e, var_mean)
}
plot(critfast_each_k, type = "l", xlab = "k = 1:K", ylab = "Fast Criterion", axes = F)
box()

crit1atatime_each_k = rep(NA, K)
for(i in 1:K){
  crit1atatime_each_k[i] = crit_1atatime(X_fast$D[ , i], k = 4, N, mean_beta0, mean_beta1, var_e, var_mean)
}
plot(crit1atatime_each_k, type = "l", xlab = "k = 1:K", ylab = "One-at-a-Time Criterion", axes = F)
box()
```

\tiny

- Total Potential Energy criterion starts to increase as the design approaches `K = 20`. It could be that `K = 20` is too large
- Variance on Slope ($\hat{\beta}$) also increases. However, this makes sense since it is mainly a function of the differences between design points and their mean.




## One-at-a-Time Criterion, Different k Powers

- To see if it decreases as $k \rightarrow \infty$, since this algorithm is supposed to be the asymptotic result of the one-at-a-time algorithm, here are the results for $k = 1:100$.

- For the fast algorithm's design, the one-at-a-time algorithm's criterion approaches the fast algorithm's criterion as k gets large (until it becomes `infty`. Compuational issue, probably.)

\tiny
```{r, fig.height = 6}
maxk = 100
crit1atatime_diffk = rep(NA, maxk)
for(i in 1:maxk){
  crit1atatime_diffk[i] = crit_1atatime(X_fast_K, k = i, N, mean_beta0, mean_beta1, var_e, var_mean)
}
plot(crit1atatime_diffk, type = "l", xlab = "k = 1:100", ylab = "One-at-a-Time Criterion", ylim = c(40000, 95000))
abline(a = c1_fast, b = 0, col = 2)
abline(v = 4, col = 3)
legend("topright", legend = c("k = 4", "fast crit"), col = c(3, 2), lty = rep(1, 1))
```



# One-at-a-Time Algorithm

## Design generated by One-at-a-Time Algorithm

```{r alg2run, cache = TRUE}
mean_beta0 = 1 # slope of null model
mean_beta1 = 1 / 2 # slope of alternative model
var_mean = 0.001 # variance on beta
var_e = 0.01 # variance on error

xmin = 0 
xmax = 1 

f0 = function(x) mean_beta0 * x # null regression model
f1 = function(x) mean_beta1 * x # alternative regression model

N = 67
# for one-at-a-time algorithm:
numCandidates = 10^5 # suggested 10^5
k = 4

# One-at-a-Time Algorithm
X_1atatime = SMED_ms(mean_beta0 = mean_beta0, mean_beta1 = mean_beta1, var_e = var_e, var_mean = var_mean, N = N, numCandidates = numCandidates, k = k, xmin = xmin, xmax = xmax)
```

```{r, fig.height = 6}
par(mfrow = c(1, 2))
# design points locations
curve(f0, col = 1, from = xmin, to = xmax, xlab = "", ylab = "", ylim = c(0, 3), axes = F)
curve(f1, col = 1, add = TRUE)
axis(1)
y = rep(NA, N)
for(i in 1:N){
  y[i] = i * 0.04
  text(X_1atatime[i], y[i], i, col=4)
}
points(X_1atatime, rep(0, N), col = 2, pch = "*")
lines(X_1atatime, y, col = 3)
# histogram of design points
hist(X_1atatime, freq = T)
```

\tiny
```{r, echo =TRUE}
mean(X_1atatime)
sd(X_1atatime)
```


<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r, include = FALSE}
numSims = 1000
nworkers = detectCores()
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_0 --> 

```{r alg2bfh0, include = FALSE, cache = TRUE}
# Simulate several Y and average to compare Posteriors H_i | X, Y

X = X_1atatime

## 1st suppose H_0 is true, i.e. y_i = x_i beta0 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1
YH0oneattime <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta0 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta0
randSim = sample(1:numSims, 1); plot(YH0oneattime[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y (given H0) at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH0oneattime[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH0oneattime[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH0oneattime = mean(marginalY_H0); expect_margY_H1_YH0oneattime = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH0oneattime = expect_margY_H0_YH0oneattime / (expect_margY_H0_YH0oneattime + expect_margY_H1_YH0oneattime)
expect_post_H1_YH0oneattime = expect_margY_H1_YH0oneattime / (expect_margY_H0_YH0oneattime + expect_margY_H1_YH0oneattime)
BF01_YH0oneattime = expect_margY_H0_YH0oneattime / expect_margY_H1_YH0oneattime # since > 1, H0 is supported
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_1 --> 

```{r alg2bfh1, include = FALSE, cache = TRUE}
## 2nd suppose H_1 is true, i.e. y_i = x_i beta1 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1

YH1oneattime <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta1 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta1
randSim = sample(1:numSims, 1); plot(YH1oneattime[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH1oneattime[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH1oneattime[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH1oneattime = mean(marginalY_H0); expect_margY_H1_YH1oneattime = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH1oneattime = expect_margY_H0_YH1oneattime / (expect_margY_H0_YH1oneattime + expect_margY_H1_YH1oneattime)
expect_post_H1_YH1oneattime = expect_margY_H1_YH1oneattime / (expect_margY_H0_YH1oneattime + expect_margY_H1_YH1oneattime)
BF01_YH1oneattime = expect_margY_H0_YH1oneattime / expect_margY_H1_YH1oneattime # since < 1, H0 is not supported
```

<!-- Variance of Slope, Total Potential Energy, c1, c2 Evaluations --> 

```{r alg2evals}
# Regression variance of slope, not taking beta prior into account
v_oneattime = varslope(X_1atatime, var_e, var_mean)
# Total Potential Energy criterion
TPE_oneattime = totalPE(X_1atatime, N, mean_beta0, mean_beta1, var_e, var_mean)
# Fast Algorithm criterion
c1_oneattime = crit_fast(X_1atatime, N, mean_beta0, mean_beta1, var_e, var_mean)
# One-at-a-Time Algorithm criterion
c2_oneattime = crit_1atatime(X_1atatime, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean)

evals_oneattime = c(expect_post_H0_YH0oneattime, expect_post_H1_YH0oneattime, BF01_YH0oneattime, expect_post_H0_YH1oneattime, expect_post_H1_YH1oneattime, BF01_YH1oneattime, v_oneattime, TPE_oneattime, c1_oneattime, c2_oneattime, mean(X_1atatime), sd(X_1atatime))
```

## Evaluations

```{r, echo = TRUE}
# Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0oneattime, expect_post_H1_YH0oneattime, BF01_YH0oneattime)
# Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1oneattime, expect_post_H1_YH1oneattime, BF01_YH1oneattime)
# Slope Variance
v_oneattime
# Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_oneattime, c1_oneattime, c2_oneattime)
```



## Robustness Across k Power

```{r alg2diffk, cache = TRUE}
maxk = 20
X_1atatime_diffk = matrix(rep(NA, N * maxk), N, maxk)
for(i in 1:maxk){
  X_1atatime_diffk[ , i] = SMED_ms(mean_beta0 = mean_beta0, mean_beta1 = mean_beta1, var_e = var_e, var_mean = var_mean, N = N, numCandidates = 1000, k = i, xmin = xmin, xmax = xmax)
}
```

```{r}
v_1atatime_diffk = rep(NA, maxk)
TPE_1atatime_diffk = rep(NA, maxk)
c1_1atatime_diffk = rep(NA, maxk)
c2_1atatime_diffk = rep(NA, maxk)

for(i in 1:maxk){
  v_1atatime_diffk[i] = varslope(X_1atatime_diffk[ , i], var_e, var_mean)
  TPE_1atatime_diffk[i] = totalPE(X_1atatime_diffk[ , i], N, mean_beta0, mean_beta1, var_e, var_mean)
  c1_1atatime_diffk[i] = crit_fast(X_1atatime_diffk[ , i], N, mean_beta0, mean_beta1, var_e, var_mean)
  c2_1atatime_diffk[i] = crit_1atatime(X_1atatime_diffk[ , i], N, k = i, mean_beta0, mean_beta1, var_e, var_mean)
}
```

```{r}
# PLOT!
par(mfrow = c(2, 2))

plot(v_1atatime_diffk, type = "l", xlab = "k = 1:maxk", ylab = "Slope Variance", axes = F)
box(); abline(v = 4, col = 3)

plot(TPE_1atatime_diffk, type = "l", xlab = "k = 1:maxk", ylab = "Total Potential Energy", axes = F)
box(); abline(v = 4, col = 3)

plot(c1_1atatime_diffk, type = "l", xlab = "k = 1:maxk", ylab = "Fast Criterion", axes = F)
box(); abline(v = 4, col = 3)

plot(c2_1atatime_diffk, type = "l", xlab = "k = 1:maxk", ylab = "One-at-a-Time Criterion", axes = F)
box(); abline(v = 4, col = 3)
```

## Comparing Evaluations for Criterion



```{r, fig.height = 6}
plot(c2_1atatime_diffk, type = "l", xlab = "k = 1:maxk", ylab = "One-at-a-Time Criterion", ylim = c(40000, 95000))
abline(v = 4, col = 3)
abline(a = c1_oneattime, b = 0, col = 2)
legend("topright", legend = c("k = 4", "fast crit"), col = c(3, 2), lty = rep(1, 1))
```





# Random Design

## Random Designs

10 simulated random designs ($\mathbf{x} \sim U([0, 1]^p)$, $\forall \mathbf{x} \in \mathbf{D}_{\text{random}}$).

```{r randomrun, cache = TRUE}
numRandomDesigns = 10
N = 67

nworkers = detectCores()

# open cluster
cl = makeCluster(nworkers)
registerDoParallel(cl)

# run sims
X_random = foreach(i = 1:numRandomDesigns) %dorng% {
  runif(N)
}

# close cluster
stopCluster(cl)

X_rand = matrix(unlist(X_random), N, numRandomDesigns)
X_rand = apply(X_rand, MARGIN = 2, FUN = sort)
```

<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r randbf, include = FALSE, cache = TRUE}
##### CALC POSTERIOR PROBS AND BFs OF EACH RANDOM DESIGN #####

numSims = 100


# make cluster
cl = makeCluster(nworkers)
registerDoParallel(cl)
# generate sequence of seeds of length the number of computations
n <- numRandomDesigns; p <- numSims
rng <- RNGseq( n * p, 1234)
# run standard nested foreach loop
rand_designs_simulated_Ys <- foreach(i=1:n) %:% foreach(j=1:p, r=rng[(i-1)*p + 1:p]) %dopar% {
  
  # i is the random design being looked at.
  # j is the simulation for that particular random design. each design has numSims simulations
  
  # set RNG seed
  rngtools::setRNG(r)
  # do your own computation ...
  
  
  # --- Start Simulations --- #
  # Get X
  X = X_rand[ , i]
  
  # Simulate Y | H0
  YH0_ij = sapply(X, FUN = function(x) rnorm(n = 1, mean = mean_beta0 * x, sd = sqrt(var_e)))
  
  # Simulate Y | H1
  YH1_ij = sapply(X, FUN = function(x) rnorm(n = 1, mean = mean_beta1 * x, sd = sqrt(var_e)))
  list("i" = i, "j" = j,"X" = X, "YH0_ij" = YH0_ij, "YH1_ij" = YH1_ij)
}
stopCluster(cl)


plot(X_rand[ , rand_designs_simulated_Ys[[1]][[100]]$i], rand_designs_simulated_Ys[[1]][[100]]$YH1_ij)
plot(rand_designs_simulated_Ys[[1]][[100]]$X, rand_designs_simulated_Ys[[1]][[100]]$YH1_ij)
# same, as should be.


## COMPUTE.

# initialize cluster w specified # workers
cl = makeCluster(nworkers) # initialize cluster
registerDoParallel(cl) # open the cluster for use

## parallel simulations go here
evaluations_rand = foreach(i = 1:numRandomDesigns) %dopar% {
  # Design and its simulated Y's
  X = X_rand[ , i]
  resX = rand_designs_simulated_Ys[[i]]
  
  YH0 = matrix(rep(NA, numSims * N), N, numSims)
  for(m in 1:numSims){
    YH0[ , m] = resX[[m]]$YH0_ij
  }
  
  YH1 = matrix(rep(NA, numSims * N), N, numSims)
  for(m in 1:numSims){
    YH1[ , m] = resX[[m]]$YH1_ij
  }
  
  ### Y | H0 Calcs ###
  # calculate marginal y (given H0) at each row and column, for each model 0, 1
  marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
  for(i in 1:N){
    for(j in 1:numSims){
      marginalY_H0[i, j] = getMarginalY(YH0[i, j], mean_beta0, i)
    }
  }
  marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
  for(i in 1:N){
    for(j in 1:numSims){
      marginalY_H1[i, j] = getMarginalY(YH0[i, j], mean_beta1, i)
    }
  }
  # calculate expected marginal y for each model by averaging
  expect_margY_H0_YH0rand = mean(marginalY_H0); expect_margY_H1_YH0rand = mean(marginalY_H1)
  # calculate expected posterior probability of each model (equal prior on models) and BF
  expect_post_H0_YH0rand = expect_margY_H0_YH0rand / (expect_margY_H0_YH0rand + expect_margY_H1_YH0rand)
  expect_post_H1_YH0rand = expect_margY_H1_YH0rand / (expect_margY_H0_YH0rand + expect_margY_H1_YH0rand)
  BF01_YH0rand = expect_margY_H0_YH0rand / expect_margY_H1_YH0rand # since > 1, H0 is supported
  
  
  
  ### Y | H1 Calcs ###
  # calculate marginal y (given H1) at each row and column, for each model 0, 1
  marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
  for(i in 1:N){
    for(j in 1:numSims){
      marginalY_H0[i, j] = getMarginalY(YH1[i, j], mean_beta0, i)
    }
  }
  marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
  for(i in 1:N){
    for(j in 1:numSims){
      marginalY_H1[i, j] = getMarginalY(YH1[i, j], mean_beta1, i)
    }
  }
  # calculate expected marginal y for each model by averaging
  expect_margY_H0_YH1rand = mean(marginalY_H0); expect_margY_H1_YH1rand = mean(marginalY_H1)
  # calculate expected posterior probability of each model (equal prior on models) and BF
  expect_post_H0_YH1rand = expect_margY_H0_YH1rand / (expect_margY_H0_YH1rand + expect_margY_H1_YH1rand)
  expect_post_H1_YH1rand = expect_margY_H1_YH1rand / (expect_margY_H0_YH1rand + expect_margY_H1_YH1rand)
  BF01_YH1rand = expect_margY_H0_YH1rand / expect_margY_H1_YH1rand # since < 1, H0 is not supported
  
  c("expect_post_H0_YH0rand" = expect_post_H0_YH0rand, 
    "expect_post_H1_YH0rand" = expect_post_H1_YH0rand, 
    "BF01_YH0rand" = BF01_YH0rand, 
    "expect_post_H0_YH1rand" = expect_post_H0_YH1rand, 
    "expect_post_H1_YH1rand" = expect_post_H1_YH1rand, 
    "BF01_YH1rand" = BF01_YH1rand)
}

# stop cluster after simulations
stopCluster(cl)
```

```{r}
# get results
expect_post_H0_YH0rand_vec = rep(NA, numRandomDesigns)
expect_post_H1_YH0rand_vec = rep(NA, numRandomDesigns)
BF01_YH0rand_vec = rep(NA, numRandomDesigns)
expect_post_H0_YH1rand_vec = rep(NA, numRandomDesigns)
expect_post_H1_YH1rand_vec = rep(NA, numRandomDesigns)
BF01_YH1rand_vec = rep(NA, numRandomDesigns)
for(m in 1:numRandomDesigns) {
  resX = evaluations_rand[[m]]
  expect_post_H0_YH0rand_vec[m] = resX["expect_post_H0_YH0rand"]
  expect_post_H1_YH0rand_vec[m] = resX["expect_post_H1_YH0rand"]
  BF01_YH0rand_vec[m] = resX["BF01_YH0rand"]
  expect_post_H0_YH1rand_vec[m] = resX["expect_post_H0_YH1rand"]
  expect_post_H1_YH1rand_vec[m] = resX["expect_post_H1_YH1rand"]
  BF01_YH1rand_vec[m] = resX["BF01_YH1rand"]
}

expect_post_H0_YH0rand = mean(expect_post_H0_YH0rand_vec)
expect_post_H1_YH0rand = mean(expect_post_H1_YH0rand_vec)
BF01_YH0rand = mean(BF01_YH0rand_vec)
expect_post_H0_YH1rand = mean(expect_post_H0_YH1rand_vec)
expect_post_H1_YH1rand = mean(expect_post_H1_YH1rand_vec)
BF01_YH1rand = mean(BF01_YH1rand_vec)

```

```{r}
# Regression variance of slope, not taking beta prior into account
v_rand_vec = apply(X_rand, 2, FUN = function(x) varslope(x, var_e, var_mean))
TPE_rand_vec = apply(X_rand, 2, FUN = function(x) totalPE(x, N, mean_beta0, mean_beta1, var_e, var_mean))
crit1_rand_vec = apply(X_rand, 2, FUN = function(x) crit_fast(x, N, mean_beta0, mean_beta1, var_e, var_mean))
crit2_rand_vec = apply(X_rand, 2, FUN = function(x) crit_1atatime(x, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean))

v_rand = mean(v_rand_vec)
TPE_rand = mean(TPE_rand_vec)
crit1_rand = mean(crit1_rand_vec)
crit2_rand = mean(crit2_rand_vec)
# means
mean_evals_rand = c(expect_post_H0_YH0rand, expect_post_H1_YH0rand, BF01_YH0rand, expect_post_H0_YH1rand, expect_post_H1_YH1rand, BF01_YH1rand, v_rand, TPE_rand, crit1_rand, crit2_rand, NA, NA)


# sd's
expect_post_H0_YH0rand_sd = sd(expect_post_H0_YH0rand_vec)
expect_post_H1_YH0rand_sd = sd(expect_post_H1_YH0rand_vec)
BF01_YH0rand_sd = sd(BF01_YH0rand_vec)
expect_post_H0_YH1rand_sd = sd(expect_post_H0_YH1rand_vec)
expect_post_H1_YH1rand_sd = sd(expect_post_H1_YH1rand_vec)
BF01_YH1rand_sd = sd(BF01_YH1rand_vec)
v_rand_sd = sd(v_rand_vec)
TPE_rand_sd = sd(TPE_rand_vec)
crit1_rand_sd = sd(crit1_rand_vec)
crit2_rand_sd = sd(crit2_rand_vec)
sd_evals_rand = c(expect_post_H0_YH0rand_sd, expect_post_H1_YH0rand_sd, BF01_YH0rand_sd, expect_post_H0_YH1rand_sd, expect_post_H1_YH1rand_sd, BF01_YH1rand_sd, v_rand_sd, TPE_rand_sd, crit1_rand_sd, crit2_rand_sd)
```

\tiny
```{r, echo = TRUE}
# Mean Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0rand, expect_post_H1_YH0rand, BF01_YH0rand)
# Mean Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1rand, expect_post_H1_YH1rand, BF01_YH1rand)
# Mean Slope Variance
v_rand
# Mean Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_rand, crit1_rand, crit2_rand)

# SD Slope Variance
v_rand_sd
# SD Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_rand_sd, crit1_rand_sd, crit2_rand_sd)
```




# Space-Filling Design

## The Design Points

Where the points are in no particular order.

```{r, fig.height = 5}
X_space = seq(xmin, xmax, length.out = N)
par(mfrow = c(1, 2))
# design points locations
curve(f0, col = 1, from = xmin, to = xmax, xlab = "", ylab = "", ylim = c(0, 3), axes = F)
curve(f1, col = 1, add = TRUE)
axis(1)
y = rep(NA, N)
for(i in 1:N){
  y[i] = i * 0.04
  text(X_space[i], y[i], i, col=4)
}
points(X_space, rep(0, N), col = 2, pch = "*")
lines(X_space, y, col = 3)
# histogram of design points
hist(X_space, freq = T)
```

\tiny
```{r, echo =TRUE}
mean(X_space)
sd(X_space)
```


<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r, include = FALSE}
numSims = 1000
nworkers = detectCores()
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_0 --> 

```{r spacebfh0, include = FALSE, cache = TRUE}
# Simulate several Y and average to compare Posteriors H_i | X, Y

X = X_space

## 1st suppose H_0 is true, i.e. y_i = x_i beta0 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1
YH0space <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta0 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta0
randSim = sample(1:numSims, 1); plot(YH0space[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y (given H0) at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH0space[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH0space[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH0space = mean(marginalY_H0); expect_margY_H1_YH0space = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH0space = expect_margY_H0_YH0space / (expect_margY_H0_YH0space + expect_margY_H1_YH0space)
expect_post_H1_YH0space = expect_margY_H1_YH0space / (expect_margY_H0_YH0space + expect_margY_H1_YH0space)
BF01_YH0space = expect_margY_H0_YH0space / expect_margY_H1_YH0space # since > 1, H0 is supported
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_1 --> 

```{r spacebfh1, include = FALSE, cache = TRUE}
## 2nd suppose H_1 is true, i.e. y_i = x_i beta1 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1

YH1space <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta1 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta1
randSim = sample(1:numSims, 1); plot(YH1space[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH1space[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH1space[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH1space = mean(marginalY_H0); expect_margY_H1_YH1space = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH1space = expect_margY_H0_YH1space / (expect_margY_H0_YH1space + expect_margY_H1_YH1space)
expect_post_H1_YH1space = expect_margY_H1_YH1space / (expect_margY_H0_YH1space + expect_margY_H1_YH1space)
BF01_YH1space = expect_margY_H0_YH1space / expect_margY_H1_YH1space # since < 1, H0 is not supported
```

<!-- Variance of Slope, Total Potential Energy, c1, c2 Evaluations --> 

```{r spaceevals}
# Regression variance of slope, not taking beta prior into account
v_space = varslope(X_space, var_e, var_mean)
# Total Potential Energy criterion
TPE_space = totalPE(X_space, N, mean_beta0, mean_beta1, var_e, var_mean)
# Fast Algorithm criterion
c1_space = crit_fast(X_space, N, mean_beta0, mean_beta1, var_e, var_mean)
# One-at-a-Time Algorithm criterion
c2_space = crit_1atatime(X_space, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean)

evals_space = c(expect_post_H0_YH0space, expect_post_H1_YH0space, BF01_YH0space, expect_post_H0_YH1space, expect_post_H1_YH1space, BF01_YH1space, v_space, TPE_space, c1_space, c2_space, mean(X_space), sd(X_space))
```

## Evaluations

```{r, echo = TRUE}
# Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0space, expect_post_H1_YH0space, BF01_YH0space)
# Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1space, expect_post_H1_YH1space, BF01_YH1space)
# Slope Variance
v_space
# Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_space, c1_space, c2_space)
```








# D-Optimal Design

## D-Optimal Criterion

Seeks to minimize:

$$
|(X^TX)^{-1}|
$$
i.e. maximize:
$$
|X^TX|
$$

where $X$ is the design.

## Design generated by D-Optimal Criterion

Using `AlgDesign` package (using Federov's exchange algorithm),

```{r, doptrun}
library(AlgDesign)
numCandidates = 1000; N = 67
candidates = matrix(seq(xmin, xmax, length.out = numCandidates), numCandidates, 1)
Dopt_result = optFederov(data = candidates, nTrials = N, approximate = FALSE, criterion = "D")
X_Dopt = as.vector(unlist(Dopt_result$design))
```

where the points are in no particular order... assumed to be random order?

```{r, fig.height = 4}
par(mfrow = c(1, 2))
# design points locations
curve(f0, col = 1, from = xmin, to = xmax, xlab = "", ylab = "", ylim = c(0, 3), axes = F)
curve(f1, col = 1, add = TRUE)
axis(1)
y = rep(NA, N)
for(i in 1:N){
  y[i] = i * 0.04
  text(X_Dopt[i], y[i], i, col=4)
}
points(X_Dopt, rep(0, N), col = 2, pch = "*")
lines(X_Dopt, y, col = 3)
# histogram of design points
hist(X_Dopt, freq = T)
```

\tiny
```{r, echo =TRUE}
mean(X_Dopt)
sd(X_Dopt)
```


<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r, include = FALSE}
numSims = 1000
nworkers = detectCores()
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_0 --> 

```{r doptbfh0, include = FALSE, cache = TRUE}
# Simulate several Y and average to compare Posteriors H_i | X, Y

X = X_Dopt

## 1st suppose H_0 is true, i.e. y_i = x_i beta0 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1
YH0dopt <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta0 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta0
randSim = sample(1:numSims, 1); plot(YH0dopt[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y (given H0) at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH0dopt[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH0dopt[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH0dopt = mean(marginalY_H0); expect_margY_H1_YH0dopt = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH0dopt = expect_margY_H0_YH0dopt / (expect_margY_H0_YH0dopt + expect_margY_H1_YH0dopt)
expect_post_H1_YH0dopt = expect_margY_H1_YH0dopt / (expect_margY_H0_YH0dopt + expect_margY_H1_YH0dopt)
BF01_YH0dopt = expect_margY_H0_YH0dopt / expect_margY_H1_YH0dopt # since > 1, H0 is supported
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_1 --> 

```{r doptbfh1, include = FALSE, cache = TRUE}
## 2nd suppose H_1 is true, i.e. y_i = x_i beta1 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1

YH1dopt <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta1 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta1
randSim = sample(1:numSims, 1); plot(YH1dopt[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH1dopt[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH1dopt[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH1dopt = mean(marginalY_H0); expect_margY_H1_YH1dopt = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH1dopt = expect_margY_H0_YH1dopt / (expect_margY_H0_YH1dopt + expect_margY_H1_YH1dopt)
expect_post_H1_YH1dopt = expect_margY_H1_YH1dopt / (expect_margY_H0_YH1dopt + expect_margY_H1_YH1dopt)
BF01_YH1dopt = expect_margY_H0_YH1dopt / expect_margY_H1_YH1dopt # since < 1, H0 is not supported
```

<!-- Variance of Slope, Total Potential Energy, c1, c2 Evaluations --> 

```{r doptevals}
# Regression variance of slope, not taking beta prior into account
v_dopt = varslope(X_Dopt, var_e, var_mean)
# Total Potential Energy criterion
TPE_dopt = totalPE(X_Dopt, N, mean_beta0, mean_beta1, var_e, var_mean)
# Fast Algorithm criterion
c1_dopt = crit_fast(X_Dopt, N, mean_beta0, mean_beta1, var_e, var_mean)
# One-at-a-Time Algorithm criterion
c2_dopt = crit_1atatime(X_Dopt, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean)

evals_dopt = c(expect_post_H0_YH0dopt, expect_post_H1_YH0dopt, BF01_YH0dopt, expect_post_H0_YH1dopt, expect_post_H1_YH1dopt, BF01_YH1dopt, v_dopt, TPE_dopt, c1_dopt, c2_dopt, mean(X_Dopt), sd(X_Dopt))
```

## Evaluations

```{r, echo = TRUE}
# Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0dopt, expect_post_H1_YH0dopt, BF01_YH0dopt)
# Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1dopt, expect_post_H1_YH1dopt, BF01_YH1dopt)
# Slope Variance
v_dopt
# Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_dopt, c1_dopt, c2_dopt)
```




# ...










## Design generated by A-Optimal Criterion

Using `AlgDesign` package (using Federov's exchange algorithm),

```{r, aoptrun}
library(AlgDesign)
numCandidates = 1000; N = 67
candidates = matrix(seq(xmin, xmax, length.out = numCandidates), numCandidates, 1)
Aopt_result = optFederov(data = candidates, nTrials = N, approximate = FALSE, criterion = "A")
X_Aopt = as.vector(unlist(Aopt_result$design))
```

```{r, fig.height = 4}
par(mfrow = c(1, 2))
# design points locations
curve(f0, col = 1, from = xmin, to = xmax, xlab = "", ylab = "", ylim = c(0, 3), axes = F)
curve(f1, col = 1, add = TRUE)
axis(1)
y = rep(NA, N)
for(i in 1:N){
  y[i] = i * 0.04
  text(X_Aopt[i], y[i], i, col=4)
}
points(X_Aopt, rep(0, N), col = 2, pch = "*")
lines(X_Aopt, y, col = 3)
# histogram of design points
hist(X_Aopt, freq = T)
```

\tiny
```{r, echo =TRUE}
mean(X_Aopt)
sd(X_Aopt)
```


<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r, include = FALSE}
numSims = 1000
nworkers = detectCores()
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_0 --> 

```{r aoptbfh0, include = FALSE, cache = TRUE}
# Simulate several Y and average to compare Posteriors H_i | X, Y

X = X_Aopt

## 1st suppose H_0 is true, i.e. y_i = x_i beta0 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1
YH0aopt <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta0 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta0
randSim = sample(1:numSims, 1); plot(YH0aopt[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y (given H0) at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH0aopt[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH0aopt[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH0aopt = mean(marginalY_H0); expect_margY_H1_YH0aopt = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH0aopt = expect_margY_H0_YH0aopt / (expect_margY_H0_YH0aopt + expect_margY_H1_YH0aopt)
expect_post_H1_YH0aopt = expect_margY_H1_YH0aopt / (expect_margY_H0_YH0aopt + expect_margY_H1_YH0aopt)
BF01_YH0aopt = expect_margY_H0_YH0aopt / expect_margY_H1_YH0aopt # since > 1, H0 is supported
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_1 --> 

```{r aoptbfh1, include = FALSE, cache = TRUE}
## 2nd suppose H_1 is true, i.e. y_i = x_i beta1 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1

YH1aopt <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta1 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta1
randSim = sample(1:numSims, 1); plot(YH1aopt[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH1aopt[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH1aopt[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH1aopt = mean(marginalY_H0); expect_margY_H1_YH1aopt = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH1aopt = expect_margY_H0_YH1aopt / (expect_margY_H0_YH1aopt + expect_margY_H1_YH1aopt)
expect_post_H1_YH1aopt = expect_margY_H1_YH1aopt / (expect_margY_H0_YH1aopt + expect_margY_H1_YH1aopt)
BF01_YH1aopt = expect_margY_H0_YH1aopt / expect_margY_H1_YH1aopt # since < 1, H0 is not supported
```

<!-- Variance of Slope, Total Potential Energy, c1, c2 Evaluations --> 

```{r aoptevals}
# Regression variance of slope, not taking beta prior into account
v_aopt = varslope(X_Aopt, var_e, var_mean)
# Total Potential Energy criterion
TPE_aopt = totalPE(X_Aopt, N, mean_beta0, mean_beta1, var_e, var_mean)
# Fast Algorithm criterion
c1_aopt = crit_fast(X_Aopt, N, mean_beta0, mean_beta1, var_e, var_mean)
# One-at-a-Time Algorithm criterion
c2_aopt = crit_1atatime(X_Aopt, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean)

evals_aopt = c(expect_post_H0_YH0aopt, expect_post_H1_YH0aopt, BF01_YH0aopt, expect_post_H0_YH1aopt, expect_post_H1_YH1aopt, BF01_YH1aopt, v_aopt, TPE_aopt, c1_aopt, c2_aopt, mean(X_Aopt), sd(X_Aopt))
```

## Evaluations

```{r, echo = TRUE}
# Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0aopt, expect_post_H1_YH0aopt, BF01_YH0aopt)
# Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1aopt, expect_post_H1_YH1aopt, BF01_YH1aopt)
# Slope Variance
v_aopt
# Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_aopt, c1_aopt, c2_aopt)
```














## Design generated by I-Optimal Criterion

Using `AlgDesign` package (using Federov's exchange algorithm),

```{r, ioptrun}
library(AlgDesign)
numCandidates = 1000; N = 67
candidates = matrix(seq(xmin, xmax, length.out = numCandidates), numCandidates, 1)
Iopt_result = optFederov(~., data = candidates, nTrials = N, approximate = FALSE, criterion = "I")
X_Iopt = as.vector(unlist(Iopt_result$design))
```

```{r, fig.height = 4}
par(mfrow = c(1, 2))
# design points locations
curve(f0, col = 1, from = xmin, to = xmax, xlab = "", ylab = "", ylim = c(0, 3), axes = F)
curve(f1, col = 1, add = TRUE)
axis(1)
y = rep(NA, N)
for(i in 1:N){
  y[i] = i * 0.04
  text(X_Iopt[i], y[i], i, col=4)
}
points(X_Iopt, rep(0, N), col = 2, pch = "*")
lines(X_Iopt, y, col = 3)
# histogram of design points
hist(X_Iopt, freq = T)
```

\tiny
```{r, echo =TRUE}
mean(X_Iopt)
sd(X_Iopt)
```


<!-- Expected Posterior Probabilities of & Bayes Factors --> 

```{r, include = FALSE}
numSims = 1000
nworkers = detectCores()
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_0 --> 

```{r ioptbfh0, include = FALSE, cache = TRUE}
# Simulate several Y and average to compare Posteriors H_i | X, Y

X = X_Iopt

## 1st suppose H_0 is true, i.e. y_i = x_i beta0 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1
YH0iopt <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta0 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta0
randSim = sample(1:numSims, 1); plot(YH0iopt[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y (given H0) at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH0iopt[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH0iopt[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH0iopt = mean(marginalY_H0); expect_margY_H1_YH0iopt = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH0iopt = expect_margY_H0_YH0iopt / (expect_margY_H0_YH0iopt + expect_margY_H1_YH0iopt)
expect_post_H1_YH0iopt = expect_margY_H1_YH0iopt / (expect_margY_H0_YH0iopt + expect_margY_H1_YH0iopt)
BF01_YH0iopt = expect_margY_H0_YH0iopt / expect_margY_H1_YH0iopt # since > 1, H0 is supported
```

<!-- Expected Posterior Probabilities of & Bayes Factors, Y | H_1 --> 

```{r ioptbfh1, include = FALSE, cache = TRUE}
## 2nd suppose H_1 is true, i.e. y_i = x_i beta1 + epsilon_i
# then have:

rng <- RNGseq( N * numSims, 1234)
# sequentially...
iteration <- 1

YH1iopt <- foreach(i=1:N, .combine = "rbind") %:% foreach(j=1:numSims, .combine = "c") %do% {
  # set seed
  rngtools::setRNG(rng[[iteration]])
  iteration <- iteration + 1
  rnorm(n = 1, mean = mean_beta1 * X[i], sd = sqrt(var_e))
}

# just inspecting to see if they actually follow the line  y_i = x_i beta1
randSim = sample(1:numSims, 1); plot(YH1iopt[ , randSim] ~ X)

# calculate expected evidence for each model, P(Y | H_i), 
# i.e. averaged over beta (which is why we have mean_beta in the fmla)

# calculate marginal y at each row and column, for each model
marginalY_H0 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H0[i, j] = getMarginalY(YH1iopt[i, j], mean_beta0, i)
  }
}

marginalY_H1 = matrix(rep(NA, numSims * N), nrow = N, ncol = numSims)
for(i in 1:N){
  for(j in 1:numSims){
    marginalY_H1[i, j] = getMarginalY(YH1iopt[i, j], mean_beta1, i)
  }
}
```

```{r}
# calculate expected marginal y for each model by averaging
expect_margY_H0_YH1iopt = mean(marginalY_H0); expect_margY_H1_YH1iopt = mean(marginalY_H1)
# calculate expected posterior probability of each model (equal prior on models) and BF
expect_post_H0_YH1iopt = expect_margY_H0_YH1iopt / (expect_margY_H0_YH1iopt + expect_margY_H1_YH1iopt)
expect_post_H1_YH1iopt = expect_margY_H1_YH1iopt / (expect_margY_H0_YH1iopt + expect_margY_H1_YH1iopt)
BF01_YH1iopt = expect_margY_H0_YH1iopt / expect_margY_H1_YH1iopt # since < 1, H0 is not supported
```

<!-- Variance of Slope, Total Potential Energy, c1, c2 Evaluations --> 

```{r ioptevals}
# Regression variance of slope, not taking beta prior into account
v_iopt = varslope(X_Iopt, var_e, var_mean)
# Total Potential Energy criterion
TPE_iopt = totalPE(X_Iopt, N, mean_beta0, mean_beta1, var_e, var_mean)
# Fast Algorithm criterion
c1_iopt = crit_fast(X_Iopt, N, mean_beta0, mean_beta1, var_e, var_mean)
# One-at-a-Time Algorithm criterion
c2_iopt = crit_1atatime(X_Iopt, N, k = 4, mean_beta0, mean_beta1, var_e, var_mean)

evals_iopt = c(expect_post_H0_YH0iopt, expect_post_H1_YH0iopt, BF01_YH0iopt, expect_post_H0_YH1iopt, expect_post_H1_YH1iopt, BF01_YH1iopt, v_iopt, TPE_iopt, c1_iopt, c2_iopt, mean(X_Iopt), sd(X_Iopt))
```

## Evaluations

```{r, echo = TRUE}
# Expected Post Probs and BF01 : Y | H0 Sims
c(expect_post_H0_YH0iopt, expect_post_H1_YH0iopt, BF01_YH0iopt)
# Expected Post Probs and BF01 : Y | H1 Sims
c(expect_post_H0_YH1iopt, expect_post_H1_YH1iopt, BF01_YH1iopt)
# Slope Variance
v_iopt
# Total PE, Fast Alg Crit, One-at-a-Time Alg Crit
c(TPE_iopt, c1_iopt, c2_iopt)
```



# The Table

## Results!

\tiny
```{r}
#options(digits=4)
library(knitr)
designs = data.frame(cbind(as.character(signif(evals_fast, 4)), 
                           as.character(signif(evals_oneattime, 4)), 
                           as.character(signif(mean_evals_rand, 4)), 
                           as.character(signif(evals_space, 4)), 
                           as.character(signif(evals_dopt, 4)), 
                           as.character(signif(evals_aopt, 4)), 
                           as.character(signif(evals_iopt, 4))))
rownames(designs) = c("H0 | Y, H0", "H1 | Y, H0", "BF01 | Y, H0", "H0 | Y, H1", "H1 | Y, H1", "BF01 | Y, H1", "Var Slope", "TPE", "Fast Crit", "1atTime Crit", "Mean(D)", "sd(D)")
colnames(designs) = c("Fast", "1atTime","Random", "Space", "D-opt", "A-opt", "I-opt")
kable(designs)
```

- Fast & One-at-a-Time Algorithms have highest expected Bayes Factors (when the $H_0$ is true, lowest when $H_A$ is true), and hence are better for testing.
- They also have higher variance on $\hat{\beta}$, though, which means they are not as accurate in estimating $\beta$. As expected, the $D$-optimal design is best for estimation.
- Also noticed values of `Inf` for the space-filling and $D$-optimal designs in the evaluations of each of the 3 criteria. This is to be expected in the $D$-optimal designs, since they include `0` which has gives as Wasserstein distance of 0 (in the denominator). Underestimated these by using maximum evaluation for $q$ over $i, j$, instead. $D$-optimal design - though best for estimating, is worst in criteria evaluations, as a consequence.
